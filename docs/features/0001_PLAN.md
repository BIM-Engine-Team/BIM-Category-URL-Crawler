# Website Structure Exploration System - Technical Plan

## Overview
Build an AI-powered web crawler system that automatically explores supplier websites to understand their structure and create crawling schemas for extracting architecture material product information. The system will intelligently navigate websites, build structural maps with link series detection, and generate data extraction patterns.

## Core Components and Files

### Phase 1: Data Layer and Core Types

#### New Files to Create:
- `src/models/website_node.py` - Website structure tree node model with link series support
- `src/models/link_series.py` - Link series pattern detection and grouping
- `src/models/exploration_state.py` - Current exploration state tracking
- `src/models/crawling_schema.py` - Generated schema definitions
- `src/config/exploration_config.py` - Configuration parameters
- `src/utils/http_client.py` - HTTP client for web requests (built from scratch)

#### Core Data Structures:
```python
class LinkSeries:
    pattern_id: str
    base_pattern: str  # URL pattern template
    similar_links: List[str]  # All links matching this pattern
    sample_urls: List[str]  # Representative samples (max 3-5)
    series_type: str  # 'pagination', 'category_listing', 'product_variants'
    confidence: float
    explored_samples: Set[str]

class WebsiteNode:
    url: str
    node_type: str  # 'category', 'product', 'listing', 'navigation', 'link_series'
    parent_url: Optional[str]
    children: List[str]
    link_series: Optional[LinkSeries]  # For nodes representing link series
    page_structure: Dict
    confidence_score: float
    exploration_status: str  # 'pending', 'explored', 'skipped', 'represented_by_series'

class ExplorationState:
    root_url: str
    visited_urls: Set[str]
    tree_structure: Dict[str, WebsiteNode]
    link_series_patterns: Dict[str, LinkSeries]
    exploration_queue: List[str]
    current_depth: int
    max_depth: int
```

### Phase 2A: Website Exploration Engine

#### New Files to Create (Built from Scratch):
- `src/explorer/web_explorer.py` - Main exploration orchestrator
- `src/explorer/page_analyzer.py` - Individual page structure analysis
- `src/explorer/link_classifier.py` - Classify and prioritize discovered links
- `src/explorer/link_series_detector.py` - Detect and group similar link patterns
- `src/explorer/similarity_detector.py` - Detect patterns in similar pages

#### Key Functions:

**`src/explorer/web_explorer.py`:**
- `explore_website(root_url: str) -> WebsiteTree` - Main exploration entry point
- `analyze_homepage(url: str) -> PageStructure` - Initial homepage analysis
- `build_exploration_queue(page_structure: PageStructure) -> List[ExplorationTask]` - Generate exploration tasks
- `execute_exploration_round() -> None` - Execute one round of exploration

**`src/explorer/page_analyzer.py`:**
- `extract_page_structure(html_content: str) -> PageStructure` - Parse HTML into structured format
- `identify_content_sections(soup: BeautifulSoup) -> Dict[str, Element]` - Find main content areas
- `extract_navigation_links(soup: BeautifulSoup) -> List[Link]` - Get navigation elements
- `detect_product_indicators(soup: BeautifulSoup) -> ProductSignals` - Look for product-related content

**`src/explorer/link_classifier.py`:**
- `classify_link_type(link: Link, context: PageContext) -> LinkType` - Determine link purpose
- `calculate_exploration_priority(link: Link) -> float` - Assign exploration priority
- `filter_relevant_links(links: List[Link]) -> List[Link]` - Filter architecture-related links

**`src/explorer/link_series_detector.py`:**
- `detect_link_series(links: List[Link]) -> List[LinkSeries]` - Identify similar link patterns
- `extract_url_pattern(urls: List[str]) -> str` - Generate URL pattern template
- `group_by_similarity(links: List[Link]) -> Dict[str, List[Link]]` - Group similar links
- `select_representative_samples(series: LinkSeries) -> List[str]` - Choose samples for exploration
- `classify_series_type(series: LinkSeries) -> str` - Determine series type (pagination, categories, etc.)

**`src/explorer/similarity_detector.py`:**
- `detect_listing_patterns(nodes: List[WebsiteNode]) -> List[Pattern]` - Find repeated structures
- `identify_product_page_template(nodes: List[WebsiteNode]) -> Template` - Extract product page patterns
- `merge_similar_branches(tree: WebsiteTree) -> WebsiteTree` - Consolidate similar paths

### Phase 2B: Intelligent Navigation Algorithm with Link Series Handling

#### Algorithm: Breadth-First with Priority Scoring and Series Detection

1. **Homepage Analysis:**
   - Parse homepage HTML using custom HTTP client
   - Extract navigation menus, category links, search functionality
   - Identify potential product catalog entry points
   - Score links based on relevance to architecture materials

2. **Link Series Detection and Handling:**
   - **Series Identification:** Detect groups of similar links (e.g., "page1", "page2", "page3" or "category-A", "category-B", "category-C")
   - **Pattern Extraction:** Generate URL patterns using regex/template matching
   - **Sample Selection:** Choose 3-5 representative samples from each series instead of exploring all
   - **Series Classification:** Determine if series represents pagination, category listings, or product variants
   - **Efficient Exploration:** Only explore samples, mark others as "represented_by_series"

3. **Link Prioritization:**
   - Content relevance score (architecture, materials, products keywords)
   - Structural importance (main navigation vs footer links)
   - Series representativeness (prioritize diverse samples over similar links)
   - Depth penalty (prefer broader exploration first)

4. **Exploration Strategy:**
   - Maintain exploration queue sorted by priority
   - Track visited URLs and link series patterns
   - Implement depth limits and page count limits with series-aware counting
   - Handle dynamic content and JavaScript-rendered pages
   - Skip individual links that are part of detected series

5. **Tree Construction with Series Support:**
   - Build hierarchical website structure with link series nodes
   - Create special "link_series" nodes that represent entire series patterns
   - Store series metadata (pattern, total count, explored samples)
   - Classify pages by type including series types
   - Merge similar exploration branches into series representations

### Phase 2C: Schema Generation

#### New Files to Create:
- `src/schema/schema_generator.py` - Generate crawling schemas from exploration data
- `src/schema/pattern_extractor.py` - Extract data patterns from similar pages
- `src/schema/field_detector.py` - Identify product data fields

#### Key Functions:

**`src/schema/schema_generator.py`:**
- `generate_crawling_schema(website_tree: WebsiteTree) -> CrawlingSchema` - Main schema generation
- `create_url_patterns(nodes: List[WebsiteNode]) -> List[UrlPattern]` - Generate URL matching patterns
- `define_extraction_rules(template: PageTemplate) -> List[ExtractionRule]` - Create field extraction rules

**`src/schema/pattern_extractor.py`:**
- `extract_product_fields(product_pages: List[WebsiteNode]) -> List[ProductField]` - Identify common product attributes
- `find_content_selectors(pages: List[WebsiteNode]) -> Dict[str, str]` - Generate CSS/XPath selectors
- `validate_extraction_patterns(patterns: List[Pattern]) -> List[Pattern]` - Test pattern reliability

## Integration Points

### Standalone System (Built from Scratch):
- Create custom HTTP client with `requests` and `BeautifulSoup4` from `requirement.txt`
- Use existing `.output` directory structure for storing exploration artifacts
- Build completely independent system with no dependencies on existing code

### Output Artifacts:
- Website structure tree with link series (JSON format in `.output/exploration/`)
- Link series patterns and metadata (JSON format in `.output/series/`)
- Generated crawling schema (JSON format in `.output/schemas/`)
- Exploration logs and analysis reports

## Configuration Parameters:
- Max exploration depth (default: 5)
- Max pages per domain (default: 500)
- Request rate limits and delays
- Content relevance keywords for architecture materials
- Exclusion patterns for irrelevant sections (legal, contact, etc.)
- Link series detection thresholds:
  - Minimum series size (default: 3)
  - Maximum samples per series (default: 5)
  - Pattern similarity threshold (default: 0.8)

## Link Series Examples:
1. **Pagination:** `/products?page=1`, `/products?page=2`, `/products?page=3`
   - Pattern: `/products?page={num}`
   - Samples: page=1, page=5, page=10

2. **Category Listings:** `/category/doors`, `/category/windows`, `/category/roofing`
   - Pattern: `/category/{category_name}`
   - Samples: doors, windows, roofing

3. **Product Variants:** `/product/123-red`, `/product/123-blue`, `/product/123-green`
   - Pattern: `/product/123-{color}`
   - Samples: red, blue (skip green)